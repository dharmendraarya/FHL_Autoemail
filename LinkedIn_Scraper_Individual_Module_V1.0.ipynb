{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "695e5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from time import sleep\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "def linkedin_extractor(profile_link):\n",
    "    list_of_name = []\n",
    "    list_of_experience = []\n",
    "    list_of_about = []\n",
    "    list_of_address = []\n",
    "    list_of_job_title = []\n",
    "    list_of_description = []\n",
    "    list_of_skills =[]\n",
    "\n",
    "    credential = open('C:/Users/kumaramar/OneDrive - Microsoft/hackathon/Auto_Email/credentials.txt')\n",
    "    line = credential.readlines()\n",
    "    username = line[0]\n",
    "    password = line[1]\n",
    "    credential.close()\n",
    "#     print('- Finish importing the login credentials')\n",
    "    sleep(2)\n",
    "\n",
    "#     t1 = time.time()\n",
    "#     print('Start-time: ', t1)\n",
    "\n",
    "\n",
    "    s = Service('C:/Users/kumaramar/OneDrive - Microsoft/hackathon/Auto_Email/chromedriver.exe')\n",
    "    driver = webdriver.Chrome(service=s)\n",
    "    driver.get('https://www.linkedin.com')\n",
    "    sleep(3)\n",
    "    driver.find_element(By.ID, 'session_key').send_keys(username)\n",
    "    driver.find_element(By.ID, 'session_password').send_keys(password)\n",
    "    sleep(2)\n",
    "    log_in_button = driver.find_element(By.CLASS_NAME, \"sign-in-form__submit-button\")\n",
    "    sleep(1)\n",
    "    log_in_button.click()\n",
    "    sleep(15)\n",
    "\n",
    "    try:\n",
    "        driver.get(profile_link)\n",
    "        sleep(15)\n",
    "    #NAME\n",
    "        name = driver.find_element(By.XPATH, \"//h1[@class='text-heading-xlarge inline t-24 v-align-middle break-words']\")\n",
    "#         list_of_name.append(name.text)\n",
    "        name_text=name.text\n",
    "        sleep(5)\n",
    "    except:\n",
    "        print('Error in profile: ', profile_link)\n",
    "        list_of_name.append('')\n",
    "        list_of_experience.append([])\n",
    "        list_of_about.append([])\n",
    "        list_of_address.append([''])\n",
    "        list_of_job_title.append('')\n",
    "        list_of_description.append([])\n",
    "        list_of_skills.append([])\n",
    "\n",
    "    \n",
    "# TITLE\n",
    "    title = driver.find_element(By.XPATH, \"//div[@class='text-body-medium break-words']\")\n",
    "#     list_of_job_title.append(title.text)\n",
    "    title_text=title.text\n",
    "    \n",
    "# ADDRESS\n",
    "    address = driver.find_elements(By.XPATH, \"//span[@class='text-body-small inline t-black--light break-words']\")\n",
    "    location=[]\n",
    "    for j in address:\n",
    "        location.append(j.text)\n",
    "        list_of_address.append(location)\n",
    "    \n",
    "\n",
    "#-----------------------------------BeautifulSoup--------------------------\n",
    "    src = driver.page_source\n",
    "    doc = BeautifulSoup(src, 'html.parser')\n",
    "    div = doc.find_all('section', class_='artdeco-card ember-view relative break-words pb3 mt2')\n",
    "\n",
    "# ABOUT\n",
    "    about_section_present= False\n",
    "    for section in div:\n",
    "        about_section = section.find_all('div', {'id': 'about'})\n",
    "        if len(about_section) != 0:\n",
    "            about_section_present=True\n",
    "            about_text= section.find_all('span', {'class': 'visually-hidden'})\n",
    "            about_each=[]\n",
    "            for bio in about_text:\n",
    "                about_each.append(bio.text)\n",
    "            list_of_about.append(about_each)\n",
    "            break;\n",
    "    if about_section_present == False: \n",
    "        about_each=[]\n",
    "        list_of_about.append(about_each)\n",
    "        \n",
    "# CHECK FOR SKILL AND EXPERIENCE SECTION\n",
    "    skill_section_present= False\n",
    "    experience_section_present=False\n",
    "    \n",
    "    for section in div:\n",
    "        skill_section = section.find_all('div', {'id': 'skills'})\n",
    "        if len(skill_section) != 0:\n",
    "            skill_section_present=True\n",
    "            break\n",
    "    \n",
    "    for section in div:\n",
    "        exp_section = section.find_all('div', {'id': 'experience'})\n",
    "        if len(exp_section) != 0:\n",
    "            experience_section_present=True\n",
    "            break\n",
    "    \n",
    "    get_url = driver.current_url\n",
    "\n",
    "\n",
    "# EXPERIENCE\n",
    "\n",
    "    if experience_section_present==True:\n",
    "        sleep(3)\n",
    "        driver.get(get_url+\"details/experience\")\n",
    "        sleep(7)\n",
    "        src2 = driver.page_source\n",
    "        doc2 = BeautifulSoup(src2, 'html.parser')\n",
    "        exp_list = doc2.find_all('li', {'class':'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated'})\n",
    "        \n",
    "        experience_per_person=[]\n",
    "        for each_exp in exp_list:\n",
    "            text_line_list= each_exp.find_all('span', {'class': 'visually-hidden'})\n",
    "            partition_list=[]\n",
    "            for text_line in text_line_list:\n",
    "                partition_list.append(text_line.text)\n",
    "            experience_per_person.append(partition_list)\n",
    "        list_of_experience.append(experience_per_person)\n",
    "        \n",
    "        \n",
    "\n",
    "# SKILLS\n",
    "   \n",
    "    if skill_section_present==True:\n",
    "        sleep(3)\n",
    "        driver.get(get_url+\"details/skills\")\n",
    "        driver.maximize_window()\n",
    "\n",
    "        SCROLL_PAUSE_TIME = 0.8\n",
    "#-----------------------------------------------\n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "#------------------------------------------------                \n",
    "        print(\"Scrolling is over\")   \n",
    "        sleep(5)\n",
    "        skill_each=[]\n",
    "        src1 = driver.page_source\n",
    "        doc1 = BeautifulSoup(src1, 'html.parser')\n",
    "        div1 = doc1.find_all('li', {'class':'pvs-list__paged-list-item'}) \n",
    "\n",
    "        for li in div1:\n",
    "            only_skill=[]\n",
    "            skill_text= li.find_all('span', {'class': 'visually-hidden'})\n",
    "            for skills in skill_text:\n",
    "                only_skill.append(skills.text)\n",
    "            skill_each.append(only_skill[0])\n",
    "        list_of_skills.append(list(set(skill_each)))\n",
    "\n",
    "    elif skill_section_present == False: \n",
    "        skill_each=[]\n",
    "        list_of_skills.append(skill_each)\n",
    "        \n",
    "#     print(list_of_name)\n",
    "#     print(list_of_job_title) \n",
    "#     print(list_of_address)\n",
    "#     print(list_of_about)\n",
    "#     print(list_of_experience)\n",
    "#     for m in list_of_skills:\n",
    "#         print(len(m),m)\n",
    "    sleep(8)\n",
    "    driver.quit()\n",
    "\n",
    "#     t2 = time.time()\n",
    "#     print('End-time: ', t2)\n",
    "#     print('Total time taken: ', (t2-t1)/60, 'minutes\\t')\n",
    "\n",
    "    experience=[]\n",
    "    for exp in experience_per_person:\n",
    "        for token in exp:\n",
    "            experience.append(token)\n",
    "        experience += [\".\"]\n",
    "    experience = \" \".join(experience)\n",
    "    skills= \",\".join(skill_each)\n",
    "    return {\n",
    "        'name':name_text,\n",
    "        'profile':title_text +\" \"+ about_each[1] + \" \" +  experience + \" \" + skills}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a19d036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolling is over\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Reetabrata Har',\n",
       " 'profile': 'Data Science Lead Experienced in building and leading teams on projects covering the entire spectrum of Data Science and Analytics. In-depth knowledge of Mathematical and Statistical Modeling, Machine Learning, Programming, Data Warehousing and Data Engineering techniques. Background in working for start-ups, global organizations and in academia.  Director, Data and Business Intelligence Coda Payments Jan 2021 - Present · 1 yr 9 mos Singapore . GoBear 5 yrs 7 mos Singapore Director, Technical Product Management Jan 2019 - Dec 2020 · 2 yrs Director Of Analytics Jan 2018 - Dec 2018 · 1 yr Data Scientist Jun 2015 - Dec 2017 · 2 yrs 7 mos . Actuary Data Analyst Aon Jan 2014 - May 2015 · 1 yr 5 mos Singapore . Machine Learning,Statistical Modeling,Data Engineering,Data Science,Cloud Computing,Product Development,Python,R,SQL,Hadoop,Google Cloud Platform (GCP),Amazon Web Services (AWS),Natural Language Processing (NLP),Data Monetization,Apache Spark,Apache Airflow,Machine Learning,Statistical Modeling,Data Engineering,Data Science,Cloud Computing,Product Development,Natural Language Processing (NLP),Data Monetization,Apache Spark,Python,R,SQL,Hadoop,Google Cloud Platform (GCP),Amazon Web Services (AWS),Apache Airflow'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp= linkedin_extractor('https://www.linkedin.com/in/reetabratahar/')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e835d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = - Finish importing the login credentials\n",
    "Start-time:  1663697615.104854\n",
    "Scrolling is over\n",
    "End-time:  1663697698.6444213\n",
    "Total time taken:  1.3923261205355326 minutes\t\n",
    "{'name': 'Reetabrata Har',\n",
    " 'title': 'Data Science Lead',\n",
    " 'about': 'Experienced in building and leading teams on projects covering the entire spectrum of Data Science and Analytics. In-depth knowledge of Mathematical and Statistical Modeling, Machine Learning, Programming, Data Warehousing and Data Engineering techniques. Background in working for start-ups, global organizations and in academia. ',\n",
    " 'experience': 'Director, Data and Business Intelligence Coda Payments Jan 2021 - Present · 1 yr 9 mos Singapore . GoBear 5 yrs 7 mos Singapore Director, Technical Product Management Jan 2019 - Dec 2020 · 2 yrs Director Of Analytics Jan 2018 - Dec 2018 · 1 yr Data Scientist Jun 2015 - Dec 2017 · 2 yrs 7 mos . Actuary Data Analyst Aon Jan 2014 - May 2015 · 1 yr 5 mos Singapore .',\n",
    " 'skill': 'Machine Learning,Statistical Modeling,Data Engineering,Data Science,Cloud Computing,Product Development,Python,R,SQL,Hadoop,Google Cloud Platform (GCP),Amazon Web Services (AWS),Natural Language Processing (NLP),Data Monetization,Apache Spark,Apache Airflow,Machine Learning,Statistical Modeling,Data Engineering,Data Science,Cloud Computing,Product Development,Natural Language Processing (NLP),Data Monetization,Apache Spark,Python,R,SQL,Hadoop,Google Cloud Platform (GCP),Amazon Web Services (AWS),Apache Airflow'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fba9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp={'Name':'Reetabrata Har',\n",
    "# 'title':'Data Science Lead',\n",
    "# 'about': ['About', 'Experienced in building and leading teams on projects covering the entire spectrum of Data Science and Analytics. In-depth knowledge of Mathematical and Statistical Modeling, Machine Learning, Programming, Data Warehousing and Data Engineering techniques. Background in working for start-ups, global organizations and in academia. '],\n",
    "# 'experience':[['Director, Data and Business Intelligence', 'Coda Payments', 'Jan 2021 - Present · 1 yr 9 mos', 'Singapore'], ['GoBear', '5 yrs 7 mos', 'Singapore', 'Director, Technical Product Management', 'Jan 2019 - Dec 2020 · 2 yrs', 'Director Of Analytics', 'Jan 2018 - Dec 2018 · 1 yr', 'Data Scientist', 'Jun 2015 - Dec 2017 · 2 yrs 7 mos'], ['Actuary Data Analyst', 'Aon', 'Jan 2014 - May 2015 · 1 yr 5 mos', 'Singapore']],\n",
    "# 'skill': ['Apache Spark', 'Machine Learning', 'Data Monetization', 'Google Cloud Platform (GCP)', 'Statistical Modeling', 'Product Development', 'Amazon Web Services (AWS)', 'R', 'SQL', 'Apache Airflow', 'Data Science', 'Hadoop', 'Cloud Computing', 'Data Engineering', 'Natural Language Processing (NLP)', 'Python']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
